# Saturday, April 19th

## Brain Dump
1. Need a way to convert the PDF with all the Table 1 scans into images that can be processed
2. Basically take the scanned PDF, seperate each image, process each image through OCR
(OCR is what makes it gray scale), then use tesseract to do text extraction
3. Not entirely sure yet on how I want to store the data/what data structure I want to use
4. But data extracted should be seperated by age and month, since that's what determines the
other unique parameters of the test

## Processing Code Output
Table B.1: Verbal and Nonverbal Standard Scores, Confidence Intervals, and Percentile Ranks
| Ages 4:4-4:5 4:4-4:5
VERBAL NONVERBAL
Stand. 90% ile Raw | Stand. 90% ile Stand. 90%
Score | Score Conf. int. Rank Score | Score Conf. Int. Rank Score | Score Conf. Int. rile
108 | 160 148-165 >99.9 51 145 134-151 99.9 46 160 142-164 =k
107. | 160 148-165 >99.9 50 144 133-150 99.8 45 160 142-164 2229
106 | 160 148-165 >99.9 49 143 132-149 99.8 44 160 142-164 2008
105 | 160 148-165 >99.9 48 142. 131-148 = 99.7 43 160 449-164 2229
104 | 160 148-165 >99.9 47 141 130-147. 99.7 42 160 142-164 er
103 | 160 148-165 >99.9 46 140 129-146 99.6 41 160 142-164 5990
102 | 160 148-165 >99.9 45 139 129-145 99.5 40 160 142-164 =a58
101 | 160 148-165 399.9 a4 | 137 127-143 99 39 | 160 142-164 3993
__ 100 | 160 148-165 >999 | | 43 136 126-142 99 | _38 160__142-164 5999
99 | 160 148-165 >99.9 42 135. 125-141 99 37 | 159 141-163 S999~
98 160 148-165 >99.9 Al 133 123-139 99 36 159 141-163 3999
97 160__ 148-165 >99.9 40 132___122-138__ 98 35 158 140-162 3999
96 160 148-165 399.9 39 131 (121-138 = 98 157 139-162 999
95 160 148-165 >99.9 38 130 120-137 98 155 137-160 3999
94 160___ 148-165 >99.9 37 128 118-135 97 154 137-159 5999
93 160 148-165 >99.9 36 126 116-133 96 152 135-157 3999
92 160 148-165 >99.9 35 125. 115-132 95 150 133-155 999
91 160 148-165 >99.9 34 124 114-131 95 148 131-154 999
90 160 148-165 >99.9 EF) 122. 112-129 93 28 146 129-152 999
89 160 148-165 >99.9 32 121. 112-128 92 27 143 127-149 998
88 160 148-165 >99.9 31 119 110-126 90 26 142 126-148 997
Cy] 160 148-165 >99.9 30 117. 108-124 87 25 140 124-147 99.6
86 160 148-165 >99.9 29 116 107-123 86 24 137. 122-144 99
85 160 148-165 >99.9 28 114 105-122 82 23 135 120-1429
84 160 148-165 >99.9 27 112 103-120 79 22 132 117-139 98
83 160 148-165 >99.9 26 110 101-118 = 75 21 129 114-137 97
82 160 148-165 >99.9 25 107. 98-115 «68 20 127 113-135 9%
81 160 148-165 >99.9 106 97-114 66 124 110-132 95
80 160 148-165 >99.9 104 95-112 61 121 107-130 92
79 160 148-165 >99.9 102. 94-110 55 118 105-127 88
78 160 148-165 >99.9 99 91-107 47 115 102-124 84
77 160 148-165 >99.9 97 89-105 42 112 99-122 79
76 160 148-165 >99.9 9587-10437 108° 96-118 70
75 160 148-165 >99.9 18 92 84-101 30 103. 91-114 ‘58
74 160 148-165 >99.9 17 90 82-99 25 99 88-110 47
73 160 148-165 >99.9 16 8779-96 —:19 95 84-107__—37
72 160 148-165 >99.9 15 8 78-94 16 10 91. 81-103. 27
71 159 147-164 >99.9 14 82 75-91 12 ) 88 78-101 21
70 159 147-164 _ >99.9 13 80-73-89 9 8 84-75-97 ___—si14
7) 159 147-164 >99.9 77-70-87 6 7 80. 71-93. «9
68 158 146-163 >99.9 75 68-85 5 6 77 ~—s«68-91 6
67 158 146-163 >99.9 7366-83 4 5 73-65-87. 4
66 158 146-163 >99.9 ) 71-64-81 3 4 69. 61-84 2
65 157 146-162 >99.9 8 68 62-78 2 3 65 58-80 1
64 156 145-161 >99.9 7 66 _—-60-76 1 2 61 5477 05
63 155 144-160 >99.9 6458-74 1 1 58 52-74 (03
62 154 143-159 >99.9 62 56-72 1 0 55 49-71—Ss«C
__ 61 | 154 143-159 >99.9_ 60 5471 0.4
60 153. 142-158 >99.9 58 52-6903
59 152 141-157 >99.9 56 650-67 = 0.2
58 151 140-156__>99.9 54 48-650.
57 150 139-155 >99.9 53-47-64 0.1
56 150 139-155 >99.9
55 149 138-155 __>99.9
54 148 137-154 99.9
53 147 136-153 99.9
52 146 135-152 99.9
ae
80 Table B.1: Verbal and Nonverbal Norms, Ages 4:4~-4:5


## Redefinining Pipeline
1. Have the PDF with all the Table B.1 pages
2. To use OCR, I need to convert all the PDF pages to their PNG versions -> 
contain this in processPDF() 
3. Then, to extract meaningful data, I need to split these PNG images into
the verbal and nonverbal tables
4. Finally, I need to extract the text

### Splitting Image to Extract Table Data
1. Assuming I have a PNG of the table file, I want to split it into the three
tables on the page. I plan to do this by looking for vertical lines:

Verbal (Table 1):
Start Line: 1, End Line: 3

Verbal (Table 2):
Start Line: 4, End Line: 6

Nonverbal (Table 3):
Start Line: 7, End Line: 9

2. Then, I want to find the location for each of the vertical lines
3. Using the location for each, I want to create three new PNGs, store
them in a new folder
4. Then, I want to create an algorithm to extract the text from 
each of these pages. This is easier, because it's just recognizing
the same four columns and turning it into a data structure I can run this
on all the images for. 


## Finding Location of Vertical Lines:
Tutorial: https://www.youtube.com/watch?v=E_NRYxJyZlg

- Mask: Binary black-and-white images, allows us to specify which regions
we're interested in (usually white)
- Erosion: Removing elements
- Dilation: Expanding or growing elements
- Kernels: What you specify, this is how you decide how to change the image
to create the mask you want

This is the algorithm I want to implement based on the video:

1. For my project, to split each image, I want to make the vertical lines
white (this is what I want information on), and the rest of the image, with
the number values, black
2. This is just temporarily, because to find the split points, I'm only interested 
in where the black lines are
3. I will have to create a kernel that's a thin vertical line, because
that's the element I want to isolate for this step
4. Use getStructuringElement, because I want a line, this will be a rectangle
5. Note on syntax: this will be getStructuringElement(element, (width, height))
6. Erode the table image (it'll just be a white screen with black lines,
these black lines are the table lines)
7. Get the location of the black lines

Pseudocode:
def getVerticalLinesPositions(filePath):
    create thresholded image (inverted black and white)
    create image with only vertical lines remaining
    find location of each vertical line

## Finding Contours:
Resource: https://docs.opencv.org/4.x/d4/d73/tutorial_py_contours_begin.html
Use cv2.findContours(image, mode, method) to find the contours.
image: The binary input image.
mode: Contour retrieval mode, e.g., cv2.RETR_EXTERNAL (external contours only), cv2.RETR_LIST (all contours), cv2.RETR_TREE (hierarchical contours).
method: Contour approximation method, e.g., cv2.CHAIN_APPROX_SIMPLE (compress horizontal, vertical, and diagonal segments into their end points), cv2.CHAIN_APPROX_NONE (store all contour points).